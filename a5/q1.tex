\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage[parfill]{parskip}
\graphicspath{ {.} }
\usepackage{listings}
\usepackage{xcolor}
\lstset { %
    language=C++,
    backgroundcolor=\color{black!5}, % set backgroundcolor
    basicstyle=\footnotesize,% basic font setting
}

\newcommand\floor[1]{\lfloor#1\rfloor}
\newcommand\ceil[1]{\lceil#1\rceil}

\newtheorem{theorem}{Theorem}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\title{CS 466: Algorithm Design and Analysis - Assignment 5}
\author{Qian, Yan Liang (David)}
\date{Date of submission: November 4, 2018}

\begin{document}
\newpage

\section{Question 1}

We will prove that the expected number of times $m$ is updated is $O(logn)$.

Suppose that the random permutation of the array that we use to update $m$ is given by $x_1, x_2, \ldots, x_n$. Let $U$
represent the total number of updates to $m$. Let $X_i$ represent the number of updates to $m$ caused by $x_i$. It is
trivial to see that $X_i \in \{0, 1\}$ as we will only compare $x_i$ to $m$ a single time, and an update occurs if and only if
$x_i < m$. As $m$ can only be updated by comparing it to some $x_i$, we see that $U = \sum_{i=1}^n X_i$. Thus,
$\textbf{E}(U) = \textbf{E}(\sum_{i=1}^n X_i) = \sum_{i=1}^n \textbf{E}(X_i)$ by the linearity of expectation.

To calculate $\textbf{E}(X_i)$, we make the observation that the integers are distinct and that we randomly permute the
array. Thus, $x_i$ is uniformly chosen (akin to uniform sampling without replacement) and that it has a $\dfrac{1}{n}$
probability to be the $k$th largest element in the array (since all integers are distinct and so the relative ordering
in the sorted array is fixed). Suppose we are at the $i$th iteration (i.e we are comparing $x_i < m$). $m$ is therefore
the minimum of the $i-1$ integers that came before in the permutation: $m = \min(x_1, \ldots, x_{i-1})$.  Since each
$x_i$ was placed in the permutation uniformly, we observe that the probability $\min(x_1, \ldots x_i) = x_i$ is
$\dfrac{1}{i}$. Thus, since we only update $m$ if $x_i$ is the minimum seen so far by the $i$th iteration, we have
$\textbf{E}(X_i) = 1 \times \dfrac{1}{i} + 0 = \dfrac{1}{i}$. Note that $\textbf{E}(X_1) = 1$ as $m$ starts off at
$\infty$.

Thus, we can calculate the expectation of the total number of updates like so $\textbf{E}(U) = \sum_{i=1}^n
\textbf{E}(X_i) = \dfrac{1}{1} + \dfrac{1}{2} + \dfrac{1}{3} + \ldots + \dfrac{1}{n}$, which are the harmonic
numbers. Thus, the expected number of updates to $m$ is $\textbf{E}(U) \in O(\log n)$.


\end{document}
